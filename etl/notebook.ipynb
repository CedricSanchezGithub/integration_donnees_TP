{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TRDE703 Atelier Int√©gration des Donn√©es",
   "id": "fd7d5d2acdc3555b"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T13:19:53.240320Z",
     "start_time": "2026-01-18T13:19:53.181156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "\n",
    "project_root = current_dir.parent if current_dir.name == \"etl\" else current_dir\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(f\"‚úÖ Racine du projet ajout√©e au path : {project_root}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Racine du projet ajout√©e au path : /Users/cedricsanchez/Master1/Cours/integration_donnees_TP\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T13:19:53.260697Z",
     "start_time": "2026-01-18T13:19:53.241321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from etl.shared.config import SPARK_CONFIG, MYSQL_CONFIG\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration charg√©e avec succ√®s.\")"
   ],
   "id": "ef2390298c38f5a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration charg√©e avec succ√®s.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T13:19:53.434533Z",
     "start_time": "2026-01-18T13:19:53.261316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.shell import spark\n",
    "\n",
    "json_filepath = str(project_root / \"/Users/cedricsanchez/Master1/Cours/integration_donnees_TP/data/openfoodfacts.csv\")\n",
    "\n",
    "print(f\"üìÇ Fichier cible : {json_filepath}\")\n",
    "\n",
    "# Test de lecture\n",
    "if os.path.exists(json_filepath):\n",
    "    df = spark.read.csv(json_filepath)\n",
    "    df.show(5)\n",
    "else:\n",
    "    print(\"‚ùå Fichier introuvable. V√©rifie le dossier data/raw/\")"
   ],
   "id": "cf7e6bd3f66a8281",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Fichier cible : /Users/cedricsanchez/Master1/Cours/integration_donnees_TP/data/openfoodfacts.csv\n",
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|code\\turl\\tcreato...|\n",
      "|00000002\\thttp://...|\n",
      "|00000003\\thttp://...|\n",
      "|00000004\\thttp://...|\n",
      "|00000005\\thttp://...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
