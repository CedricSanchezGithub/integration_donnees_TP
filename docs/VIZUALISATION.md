# ğŸ“‚ Documentation : etl/visualization.py

### ğŸ“„ En bref
Ce fichier est le "photographe" du projet : il capture des instantanÃ©s des donnÃ©es avant (Input) et aprÃ¨s traitement (Output) sous forme d'images statiques (PNG), permettant une validation visuelle rapide sans interface complexe.

---

### ğŸ¯ Pourquoi ce fichier ?
Dans une chaÃ®ne de traitement automatisÃ©e, on ne peut pas toujours ouvrir un tableau de bord interactif pour vÃ©rifier que tout va bien.
Ce script a deux fonctions vitales :
1.  **ContrÃ´le QualitÃ© (Input)** : VÃ©rifier dÃ¨s le dÃ©but si les donnÃ©es brutes "tiennent la route" (ex: a-t-on reÃ§u des Nutri-Scores ?).
2.  **Rapport DÃ©cisionnel (Output)** : Fournir une "preuve" visuelle du rÃ©sultat final (ex: Top 10 des marques) facile Ã  partager par email ou Ã  archiver.

---

### âš™ï¸ Comment Ã§a marche ?

Le code distingue deux moments clÃ©s :

#### 1. La photo de dÃ©part (`visualize_input`)
* **AgrÃ©gation Spark** : On demande d'abord Ã  Spark de compter les produits par catÃ©gorie (Nutri-Score A, B, C...).
* **Dessin** : On rÃ©cupÃ¨re ce petit rÃ©sumÃ© (trÃ¨s lÃ©ger) pour crÃ©er un diagramme en barres avec **Seaborn**.
* **Sauvegarde** : Le graphique est enregistrÃ© sur le disque (`input_nutriscore_distrib.png`).

#### 2. La photo d'arrivÃ©e (`visualize_output`)
* **Connexion MySQL** : On se connecte Ã  la base de donnÃ©es finale.
* **RequÃªte Analytique** : On exÃ©cute une requÃªte SQL pour trouver les marques les plus sucrÃ©es.
    * *Note* : Le code est intelligent ; si on est en "mode test" avec peu de donnÃ©es, il abaisse ses critÃ¨res de filtrage pour afficher quand mÃªme quelque chose.
* **Sauvegarde** : Le rÃ©sultat est enregistrÃ© (`output_top_sugar_brands.png`).

---

### ğŸ’¡ Le coin de l'expert (Astuces)

**Pourquoi agrÃ©ger avant de dessiner ?**
Le code fait `df_spark.groupBy(...).count().toPandas()`.
C'est une rÃ¨gle d'or en Big Data : ne jamais envoyer des millions de lignes brutes vers la librairie de dessin (Matplotlib), cela ferait exploser la mÃ©moire. On fait toujours travailler le moteur puissant (Spark) pour rÃ©sumer les donnÃ©es *avant* de les dessiner.